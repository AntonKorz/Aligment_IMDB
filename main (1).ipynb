{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **LEVEL 1**"
      ],
      "metadata": {
        "id": "Rb-yvpkuaeSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если я закомментировал какой-то код, это скорее всего значит, что его выполнение занимает много времени. В таком случае более эффективным решением будет пропустить его и сразу применить сохраненные изменения, которые будут представлены в следующем блоке кода."
      ],
      "metadata": {
        "id": "W9GI_jfJpU_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl\n",
        "!pip install accelerate>=0.20.1\n",
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "import pandas as pd\n",
        "from trl import DPOTrainer\n",
        "import random\n",
        "import json\n",
        "from transformers import Trainer, AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, TrainingArguments, DataCollatorForLanguageModeling\n",
        "import transformers\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, DistilBertForSequenceClassification, DistilBertTokenizer\n",
        "from datasets import Dataset\n",
        "from scipy.stats import entropy\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import requests\n",
        "from os import getcwd"
      ],
      "metadata": {
        "id": "QmtXd3-oY2av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wandb\n",
        "# import wandb\n",
        "\n",
        "# # чтобы отслеживать наше обучение воспользуемся библиотекой wandb\n",
        "# # тут нужно будет войти в систему через логин и пароль\n",
        "# !wandb login\n",
        "# run = wandb.init(\n",
        "#     project=\"T18\",\n",
        "# )"
      ],
      "metadata": {
        "id": "B6_RL0MAamVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В середине этого блокнота будет раздел, в котором я создаю обучающую выборку с использованием SFT и файнтюниных моделек. Чтобы избежать ожидания в течение 3 часов, вместо этого я сохранил эти датасеты, и предлагаю вам загрузить их сразу здесь."
      ],
      "metadata": {
        "id": "tnAflm6S0Eqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/AntonKorz/Aligment_IMDB/main/SFT_generated.csv'\n",
        "directory = getcwd()\n",
        "filename = directory + '/' + 'SFT_generated.csv'\n",
        "r = requests.get(url)\n",
        "f = open(filename, 'wb')\n",
        "f.write(r.content)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/AntonKorz/Aligment_IMDB/main/hinge_generated.csv'\n",
        "directory = getcwd()\n",
        "filename = directory + '/' + 'hinge_generated.csv'\n",
        "r = requests.get(url)\n",
        "f = open(filename, 'wb')\n",
        "f.write(r.content)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/AntonKorz/Aligment_IMDB/main/sigm_generated.csv'\n",
        "directory = getcwd()\n",
        "filename = directory + '/' + 'sigm_generated.csv'\n",
        "r = requests.get(url)\n",
        "f = open(filename, 'wb')\n",
        "f.write(r.content)"
      ],
      "metadata": {
        "id": "kGOr3mLMyz93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь подгрузим наши основные модельки.\n",
        "\n",
        "gpt2_model_ref - моделька, которая будет использоваться в качестве референса к KL-loss регуляризации"
      ],
      "metadata": {
        "id": "caTDrlDT3VaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка sft модели (GPT-2)\n",
        "gpt2_model_name = \"lvwerra/gpt2-imdb\"\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained(gpt2_model_name)\n",
        "gpt2_model_ref = GPT2LMHeadModel.from_pretrained(gpt2_model_name)\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(gpt2_model_name)\n",
        "if gpt2_tokenizer.pad_token is None:\n",
        "        gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
        "\n",
        "# Загрузка модели для оценки текстов (DistilBERT)\n",
        "distilbert_model_name = \"lvwerra/distilbert-imdb\"\n",
        "distilbert_model = DistilBertForSequenceClassification.from_pretrained(distilbert_model_name)\n",
        "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(distilbert_model_name)\n",
        "\n",
        "# Установка устройства (CPU или GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gpt2_model.to(device)\n",
        "gpt2_model_ref.to(device)\n",
        "distilbert_model.to(device)"
      ],
      "metadata": {
        "id": "slGL7zRuvVWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь напишем функции, которые будут нам генерировать текст и оценивать его.\n",
        "\n",
        "*Пришлось немного поэксперементировать с параметрами генерации, чтобы текст был осмысленным и при этом разным при одинаковом промте*"
      ],
      "metadata": {
        "id": "45pZNt-P4_7W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0aOxeoWul9K"
      },
      "outputs": [],
      "source": [
        "# Функция для генерации текста\n",
        "def generate_text(model, tokenizer, prompt, min_length=150, max_length=150, num_beams=50):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    attention_mask = torch.ones(input_ids.shape, device=device)\n",
        "\n",
        "    # Генерация текста\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            no_repeat_ngram_size=2,\n",
        "            do_sample=True,\n",
        "            min_length=min_length,\n",
        "            attention_mask=attention_mask,\n",
        "            # pad_token_id=pad_token_id,\n",
        "            temperature=4.0,\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "# Функция для оценки текста с использованием DistilBERT\n",
        "def get_distilbert_logits(text):\n",
        "    inputs = distilbert_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    outputs = distilbert_model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    return -float(logits[0][0])\n",
        "\n",
        "# Функция для оценки энтропии сгенерированного текста\n",
        "def token_entropy(generations, tokenizer):\n",
        "    stats = defaultdict(int)\n",
        "    num_tokens = 0\n",
        "    for example in generations:\n",
        "        tokens = tokenizer.encode(example)\n",
        "        for t in tokens:\n",
        "            if t == tokenizer.pad_token_id:\n",
        "                continue\n",
        "            stats[t] += 1\n",
        "            num_tokens += 1\n",
        "        for k in stats.keys():\n",
        "            stats[k] /= num_tokens\n",
        "    return entropy(list(stats.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте сгенерируем 5 текстов, чтобы посмотреть, что все получается"
      ],
      "metadata": {
        "id": "kLaHEIqV5iaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 5\n",
        "for i in range(N):\n",
        "    prompt = \"Review:\"\n",
        "    generated_text = generate_text(gpt2_model, gpt2_tokenizer, prompt, min_length=50, max_length=50, num_beams=5)\n",
        "    print(f\"Generated Text {i+1}: {generated_text}\")\n",
        "\n",
        "    # Расчет reward с использованием DistilBERT\n",
        "    logit = get_distilbert_logits(generated_text)\n",
        "    print(f\"DistilBERT Logit (Reward) for Text {i+1}: {logit}\\n\")"
      ],
      "metadata": {
        "id": "6IpXOlmX328g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12a5dfd-4e67-4e0a-a219-9505f75af94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 1: Review: This one's good but not worth renting. Not recommended to anyone unless you want a fun, interesting, and scary movie to see every once in a while and have no problem playing a poker game or watching a bad movie. In fact,\n",
            "DistilBERT Logit (Reward) for Text 1: -1.3136324882507324\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 2: Review: A very intelligent and well written movie with very enjoyable acting including the director's superb work, excellent direction especially in this one as he puts you through it with enthusiasm and passion to the final part. If you like suspense film, suspense suspense thriller\n",
            "DistilBERT Logit (Reward) for Text 2: 2.6438894271850586\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 3: Review: I liked the story and even the visuals. In addition, some great acting was included. If the film was released today, would you think it would deserve it to have some good special features like music, a theme park attraction? And if\n",
            "DistilBERT Logit (Reward) for Text 3: 1.7295440435409546\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 4: Review: A true story not told by a master director. I have no idea how the story was achieved, how it ended up in, and why they changed things when there was an excuse to cut a good deal out of that film - all that\n",
            "DistilBERT Logit (Reward) for Text 4: 0.4885181188583374\n",
            "\n",
            "Generated Text 5: Review: 7/10, and that's it. I was the kind of writer who'd love to have that story tell you a little more in future films, though I'd be tempted to stop at such a level. If that didn't make\n",
            "DistilBERT Logit (Reward) for Text 5: 0.7694262266159058\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь пришло время генерации нашей выборки, на которой мы будем обучать наши SLIC-HF и DPO. Для этого вначале зафиксируем небольшое количество промтов. Потом для каждого из них сгенерируем 50 ответов и оценим эти ответы. В итоге все красиво упакуем в dataframe и сохраним."
      ],
      "metadata": {
        "id": "9n-dVuFH6ScP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_prompts = [\n",
        "    'This movie', 'Director', 'Actors', 'The', 'Cinema', 'Movie',\n",
        "    'Plot summary', 'Cinematography', 'Genre', 'Script', 'Soundtrack', 'scene',\n",
        "    'Character development', 'Cinematic techniques', 'Screenplay', 'Critical reception',\n",
        "    'Box office', 'Movie quotes', 'Cinematic universe', 'Behind the scenes', 'Movie review',\n",
        "    'Filmography', 'Casting', 'Suspense', 'Opening scene', 'Movie analysis',\n",
        "    'Film production', 'Editing', 'Costume design', 'Special effects', 'Film score',\n",
        "    'Film festivals', 'Film theory', 'Movie poster', 'Film adaptation', 'Screenwriting',\n",
        "    'Film noir', 'Cinematic history', 'Documentary', 'Film technology', 'Art direction',\n",
        "    'Foreign films', 'Film awards', 'Movie premiere', 'Film industry', 'Animated films'\n",
        "]"
      ],
      "metadata": {
        "id": "R6lg3p4zIIpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generations(model, tokenizer, prompts, num_responses):\n",
        "    data = []\n",
        "    for prompt in prompts:\n",
        "        for _ in range(num_responses):\n",
        "            generated_text = generate_text(model, tokenizer, prompt, min_length=50, max_length=50, num_beams=5)\n",
        "            logits = get_distilbert_logits(generated_text)\n",
        "            data.append([prompt, generated_text, logits])\n",
        "\n",
        "    df = pd.DataFrame(data, columns=[\"Prompt\", \"Generated Text\", \"Model Score\"])\n",
        "    return df"
      ],
      "metadata": {
        "id": "V2hH6R-cZCTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сам код генерации выборки представлен ниже, однако он работает 3 часа, поэтому я предлагаю не запускать этот блок, а перейти сразу к следующему, где наша выборка просто автоматически достаётся."
      ],
      "metadata": {
        "id": "2wXUIuu-6zTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Параметры для генерации ответов\n",
        "# num_responses = 50\n",
        "\n",
        "# # Список для хранения данных\n",
        "# data = []\n",
        "\n",
        "# # Генерация ответов и оценка с помощью модели\n",
        "# for prompt in top_prompts:\n",
        "#     print(prompt)\n",
        "#     for _ in range(num_responses):\n",
        "#         generated_text = generate_text(prompt)\n",
        "#         logits = get_distilbert_logits(generated_text)\n",
        "#         data.append([prompt, generated_text, logits])\n",
        "\n",
        "# # Создание датафрейма\n",
        "# df = pd.DataFrame(data, columns=[\"Prompt\", \"Generated Text\", \"Model Score\"])\n",
        "\n",
        "# df.to_csv('SFT_generated.csv')"
      ],
      "metadata": {
        "id": "MKpJ6qsOHArQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('SFT_generated.csv')"
      ],
      "metadata": {
        "id": "0tp3KN1GKZTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4vVMhENnR42s",
        "outputId": "6dadf7f1-7d2f-47f6-e050-67a35b610c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0          Prompt  \\\n",
              "0              0      This movie   \n",
              "1              1      This movie   \n",
              "2              2      This movie   \n",
              "3              3      This movie   \n",
              "4              4      This movie   \n",
              "...          ...             ...   \n",
              "2295        2295  Animated films   \n",
              "2296        2296  Animated films   \n",
              "2297        2297  Animated films   \n",
              "2298        2298  Animated films   \n",
              "2299        2299  Animated films   \n",
              "\n",
              "                                         Generated Text  Model Score  \n",
              "0     This movie is really bad, which is good to see...    -1.650084  \n",
              "1     This movie was a joke, and should be avoided a...    -2.537610  \n",
              "2     This movie, which had some of the best acting ...     2.021652  \n",
              "3     This movie has some great camera work and some...     2.474760  \n",
              "4     This movie was very good and I think that the ...     1.405530  \n",
              "...                                                 ...          ...  \n",
              "2295  Animated films are not meant to be watched by ...    -0.957312  \n",
              "2296  Animated films in the early 70's, I think this...     2.409756  \n",
              "2297  Animated films have always been somewhat of a ...     2.207893  \n",
              "2298  Animated films of the early 20th century could...     2.261572  \n",
              "2299  Animated films are hard to watch because all o...     2.233957  \n",
              "\n",
              "[2300 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e929311f-6d66-4cf0-af33-3de784022aad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Model Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>This movie</td>\n",
              "      <td>This movie is really bad, which is good to see...</td>\n",
              "      <td>-1.650084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This movie</td>\n",
              "      <td>This movie was a joke, and should be avoided a...</td>\n",
              "      <td>-2.537610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>This movie</td>\n",
              "      <td>This movie, which had some of the best acting ...</td>\n",
              "      <td>2.021652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>This movie</td>\n",
              "      <td>This movie has some great camera work and some...</td>\n",
              "      <td>2.474760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>This movie</td>\n",
              "      <td>This movie was very good and I think that the ...</td>\n",
              "      <td>1.405530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2295</th>\n",
              "      <td>2295</td>\n",
              "      <td>Animated films</td>\n",
              "      <td>Animated films are not meant to be watched by ...</td>\n",
              "      <td>-0.957312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2296</th>\n",
              "      <td>2296</td>\n",
              "      <td>Animated films</td>\n",
              "      <td>Animated films in the early 70's, I think this...</td>\n",
              "      <td>2.409756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2297</th>\n",
              "      <td>2297</td>\n",
              "      <td>Animated films</td>\n",
              "      <td>Animated films have always been somewhat of a ...</td>\n",
              "      <td>2.207893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2298</th>\n",
              "      <td>2298</td>\n",
              "      <td>Animated films</td>\n",
              "      <td>Animated films of the early 20th century could...</td>\n",
              "      <td>2.261572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2299</th>\n",
              "      <td>2299</td>\n",
              "      <td>Animated films</td>\n",
              "      <td>Animated films are hard to watch because all o...</td>\n",
              "      <td>2.233957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2300 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e929311f-6d66-4cf0-af33-3de784022aad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e929311f-6d66-4cf0-af33-3de784022aad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e929311f-6d66-4cf0-af33-3de784022aad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b85f650b-90e5-4df5-9dd9-6510a836bb4e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b85f650b-90e5-4df5-9dd9-6510a836bb4e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b85f650b-90e5-4df5-9dd9-6510a836bb4e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дальше разобъем нашу выборку на пары, как сказано в задании и статье и представим в нужном виде, как сказано в документации TRL."
      ],
      "metadata": {
        "id": "7Pf1Wj0f7jdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "# Определяем функцию, которая преобразует DataFrame в словарь, содержащий парные данные\n",
        "def df_to_dict(df, num_pairs):\n",
        "    data = {\"prompt\": [], \"chosen\": [], \"rejected\": []}\n",
        "\n",
        "    for prompt in top_prompts:\n",
        "        new_df = df[df['Prompt'] == prompt]\n",
        "\n",
        "        for _ in range(num_pairs):\n",
        "            # Случайным образом выбираем два индекса и сортируем их для создания уникальной пар\n",
        "            pair = tuple(sorted(random.sample(range(len(new_df)), 2)))\n",
        "            data['prompt'].append(prompt)\n",
        "            score1 = new_df.iloc[pair[0]]['Model Score']\n",
        "            score2 = new_df.iloc[pair[1]]['Model Score']\n",
        "            if score1 > score2:\n",
        "              data['chosen'].append(new_df.iloc[pair[0]]['Generated Text'])\n",
        "              data['rejected'].append(new_df.iloc[pair[1]]['Generated Text'])\n",
        "            else:\n",
        "              data['chosen'].append(new_df.iloc[pair[1]]['Generated Text'])\n",
        "              data['rejected'].append(new_df.iloc[pair[0]]['Generated Text'])\n",
        "\n",
        "    return data\n",
        "\n",
        "train_dict = df_to_dict(train_df, 50)\n",
        "train = Dataset.from_dict(train_dict)"
      ],
      "metadata": {
        "id": "F0xY-jUYagoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ekp212qSVRI",
        "outputId": "0a09e387-8ad9-4fbb-e6fa-57383fd8faa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'chosen', 'rejected'],\n",
              "    num_rows: 2300\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дальше стоит определить наши параметры обучения. С ними мне пришлось немного поиграться. В основном пытался подобрать оптимальный коэффициент бета, чтобы после обучения текст получался не просто с высоким reward, но и осмысленным. Так если поставит его неудачно, то будет генерировать несвязанная последовательность из слов \"прекрасный\", \"шедевр\" и т. д.\n",
        "\n",
        "Learning rate взял из статьи.\n",
        "\n",
        "Также следует заметить, что внутри хинж лосса библиотеки TRL реализован нормализованный хинж лосс, а не хинж лосс представленный в статье SLIC-HF.\n",
        "\n",
        "В ходе обучения основная проблема была в том, что loss падал, но не очень гладко. Это конечно проблема, которую я не понял, как решать. Но несмотря на это, модельки обучились хорошо.\n"
      ],
      "metadata": {
        "id": "Gy4EQ0tc-DAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код обучения:"
      ],
      "metadata": {
        "id": "cyW0IBf2XKfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training_args = TrainingArguments(\n",
        "#     per_device_train_batch_size=8,\n",
        "#     num_train_epochs=3,\n",
        "#     learning_rate=1e-5,\n",
        "#     remove_unused_columns=False,\n",
        "#     output_dir=\"./test\",\n",
        "#     # report_to=\"wandb\",\n",
        "#     logging_steps=50,\n",
        "# )\n",
        "\n",
        "\n",
        "# dpo_trainer_hinge = DPOTrainer(\n",
        "#     gpt2_model,\n",
        "#     gpt2_model_ref,\n",
        "#     beta=0.1,\n",
        "#     train_dataset=train,\n",
        "#     tokenizer=gpt2_tokenizer,\n",
        "#     args=training_args,\n",
        "#     loss_type ='hinge',\n",
        "# )\n",
        "\n",
        "# dpo_trainer_hinge.train()"
      ],
      "metadata": {
        "id": "P1CQqn9Jgn9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запушим полученную модель на huggingface"
      ],
      "metadata": {
        "id": "8Etwl1J96Cvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()\n",
        "# dpo_trainer_hinge.model.push_to_hub(\"AntonKorznikov/gpt2_hinge\")"
      ],
      "metadata": {
        "id": "zrxS2_y-3JcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачаем запушенную модель с huggingface"
      ],
      "metadata": {
        "id": "3A5YQEv56LnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_hinge = GPT2LMHeadModel.from_pretrained('AntonKorznikov/gpt2_hinge').to(device)"
      ],
      "metadata": {
        "id": "w0XkZDBinF1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим как работает моделька:"
      ],
      "metadata": {
        "id": "Oji16OECXhVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация N текстов и расчет reward для каждого\n",
        "N = 10\n",
        "for i in range(N):\n",
        "    prompt = \"Review:\"\n",
        "    generated_text = generate_text(model_hinge, gpt2_tokenizer, prompt, min_length=50, max_length=50, num_beams=5)\n",
        "    print(f\"Generated Text {i+1}: {generated_text}\")\n",
        "\n",
        "    # Расчет reward с использованием DistilBERT\n",
        "    logit = get_distilbert_logits(generated_text)\n",
        "    print(f\"DistilBERT Logit (Reward) for Text {i+1}: {logit}\\n\")"
      ],
      "metadata": {
        "id": "dyRbUHtbVYzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52cd5ac1-54c5-46c2-ee0e-a1a3df6a7dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 1: Review: The most beautiful I saw on DVD, I gave it a perfect thumbs up and had a tremendous collection of classic scenes for me! It's perfect as a companion to The Secret and a great fun watch for all ages, plus it has an\n",
            "DistilBERT Logit (Reward) for Text 1: 2.6233034133911133\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 2: Review: I like this film! It plays very very well and it is beautiful. It is interesting both for an actor's ability to make the most of different kinds of people, as well as an artist in a way that we could relate to and\n",
            "DistilBERT Logit (Reward) for Text 2: 2.6084604263305664\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 3: Review: Very fun, I think. It has its moments but it still is still enjoyable to see the characters evolve and develop in life. The music will bring you to tears with every moment. I love watching this movie. If you enjoy acting,\n",
            "DistilBERT Logit (Reward) for Text 3: 2.4871368408203125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 4: Review: Not so much about what's been done with the whole film but a nice look into the different people involved and the way people are different. Definitely worth a watch. I recommend this to all the children who just want a good film made for\n",
            "DistilBERT Logit (Reward) for Text 4: 2.4648008346557617\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 5: Review: A good movie, it manages to capture the spirit of the characters that the writer has created. I enjoyed this in its own very unique fashion (I've also seen several better films such as, the excellent The Man who Came Home from Away\n",
            "DistilBERT Logit (Reward) for Text 5: 2.5309042930603027\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 6: Review: The excellent acting by the cinematography; the music by Kees Hoach (who directs a great ensemble) along with the production values; plus, the movie is also entertaining in its unique style, in the sense that no one will think\n",
            "DistilBERT Logit (Reward) for Text 6: 2.4200856685638428\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 7: Review: 4 out 10: A good look at a young and beautiful girl who goes out, travels and is happy. And the way she feels with her mommy and grandmother, she's a real heartwarming story about the best of everyone. I\n",
            "DistilBERT Logit (Reward) for Text 7: 2.5049376487731934\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 8: Review: The movie is so effective that the visuals are so original and it stays true to its look. There are moments moments where it has the magic of a film - like \"Baggy Boots\" - which may not necessarily be in all movies\n",
            "DistilBERT Logit (Reward) for Text 8: 2.403818130493164\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 9: Review: I watched it on a Friday with some friends (it had great soundtrack and was really well played!). I loved it; the music is perfect in different ways. And it's just the kind you don't expect any different. Highly recommended and\n",
            "DistilBERT Logit (Reward) for Text 9: 2.6237363815307617\n",
            "\n",
            "Generated Text 10: Review: Excellent. A bit of an interesting film from a young talent, very good film for those with a small budget and are looking to be entertained by the good story that develops. Highly recommend! A must get. Recommended. I saw the film\n",
            "DistilBERT Logit (Reward) for Text 10: 2.586859703063965\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь повторим все это только для sigmoid loss"
      ],
      "metadata": {
        "id": "Q4vzokE17_G6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dpo_trainer_sigm = DPOTrainer(\n",
        "#     gpt2_model,\n",
        "#     gpt2_model_ref,\n",
        "#     beta=10,\n",
        "#     train_dataset=train,\n",
        "#     tokenizer=gpt2_tokenizer,\n",
        "#     args=training_args,\n",
        "#     loss_type ='sigmoid',\n",
        "#     # peft_config=peft_config,\n",
        "# )\n",
        "\n",
        "# dpo_trainer_sigm.train()"
      ],
      "metadata": {
        "id": "nrSXQOc-NSLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()\n",
        "# dpo_trainer_sigm.model.push_to_hub(\"AntonKorznikov/gpt2_sigm\")"
      ],
      "metadata": {
        "id": "tZMunSuzomy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sigm = GPT2LMHeadModel.from_pretrained('AntonKorznikov/gpt2_sigm').to(device)"
      ],
      "metadata": {
        "id": "8Ni0Erum6ckN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация N текстов и расчет reward для каждого\n",
        "N = 10\n",
        "for i in range(N):\n",
        "    prompt = \"Review:\"\n",
        "    generated_text = generate_text(model_sigm, gpt2_tokenizer, prompt, min_length=50, max_length=50, num_beams=5)\n",
        "    print(f\"Generated Text {i+1}: {generated_text}\")\n",
        "\n",
        "    # Расчет reward с использованием DistilBERT\n",
        "    logit = get_distilbert_logits(generated_text)\n",
        "    print(f\"DistilBERT Logit (Reward) for Text {i+1}: {logit}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzJv2kgWYFsa",
        "outputId": "362a1fca-1bb6-466e-af4d-ef2f372a286f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 1: Review: I'd have liked to have gotten more from it's story. The acting and photography were superb.<br /><br />This movie was my first time looking at \"the best of America, the people that I would never see again,\n",
            "DistilBERT Logit (Reward) for Text 1: 2.2210001945495605\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 2: Review: \"It is a very moving thriller. A big action thriller but is also entertaining from an inside angle of the world of film with all the beautiful action, great actors, good story, the best score.\" Watch it now on VHS/\n",
            "DistilBERT Logit (Reward) for Text 2: 2.4629526138305664\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 3: Review: A must if you enjoy this one. It is an excellent film for its time and time again which makes a great addition in film! I had seen it last year and went it alone, it was outstanding and it's the second one of\n",
            "DistilBERT Logit (Reward) for Text 3: 2.62440824508667\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 4: Review: \"The Little Bower\" is very much an excellent movie you will enjoy seeing, with excellent editing and beautiful photography. Also very touching for those looking up at the beauty that is the \"Big\" town, \"O'Dell,\"\n",
            "DistilBERT Logit (Reward) for Text 4: 2.5553154945373535\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 5: Review: Excellent performance, excellent plot and characters, I watched it several times before I finally went home this afternoon. The movie did give us a unique story and that makes it really interesting and the rest of the cast (all actors like it) has\n",
            "DistilBERT Logit (Reward) for Text 5: 2.4355673789978027\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 6: Review: I really like the plot and it has an incredibly good message to it and that's very good for a story with good music. The acting is good too. It has great action too, in terms of the events and the characters who are\n",
            "DistilBERT Logit (Reward) for Text 6: 2.442929744720459\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 7: Review: The first of two'specials', I watched an excellent first season so I was sure of its beauty even after the episode, as it did the first time, but with all of it a perfect adaptation. This has a strong bond of\n",
            "DistilBERT Logit (Reward) for Text 7: 2.53186297416687\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 8: Review: It was fantastic, The movie is very realistic and full of great visuals. Even though it wasn't the most popular movie ever, there is always some good reviews from people who love a great film, because it is the kind of movie you\n",
            "DistilBERT Logit (Reward) for Text 8: 2.5149428844451904\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 9: Review: 8 out of 10. Definitely see the movie as well as i have already heard the previews and has it rated high for the time period. It is so great and I think this film is very funny, yet it is an action, suspense\n",
            "DistilBERT Logit (Reward) for Text 9: 2.5539870262145996\n",
            "\n",
            "Generated Text 10: Review: Great work! The movie was quite entertaining! Thank you, Michael. Very well thought out, very well written & interesting as well! I highly recommend this one. This is definitely worth a 2-star viewing. Also, one of my\n",
            "DistilBERT Logit (Reward) for Text 10: 2.614173173904419\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь настало время сгенерировать для каждой модельки небольшой нобор текстов, оценить их энтропию и положительную\\негативную тональность."
      ],
      "metadata": {
        "id": "rxB6mX4iYYeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hinge = get_generations(model_hinge, tokenizer=gpt2_tokenizer, prompts=top_prompts, num_responses=3)\n",
        "df_sigm = get_generations(model_sigm, tokenizer=gpt2_tokenizer, prompts=top_prompts, num_responses=3)"
      ],
      "metadata": {
        "id": "4XuFkerJYm6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('SFT')\n",
        "print('Энтропия: ', token_entropy(train_df[\"Generated Text\"], gpt2_tokenizer))\n",
        "print('Reward: ', np.mean([get_distilbert_logits(text) for text in train_df[\"Generated Text\"]]))\n",
        "\n",
        "print('\\nHinge')\n",
        "print('Энтропия: ', token_entropy(df_hinge[\"Generated Text\"], gpt2_tokenizer))\n",
        "print('Reward: ', np.mean([get_distilbert_logits(text) for text in df_hinge[\"Generated Text\"]]))\n",
        "\n",
        "print('\\nSigmoid')\n",
        "print('Энтропия: ', token_entropy(df_sigm[\"Generated Text\"], gpt2_tokenizer))\n",
        "print('Reward: ', np.mean([get_distilbert_logits(text) for text in df_sigm[\"Generated Text\"]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UXE1NI2d8Ow",
        "outputId": "93c26252-55db-44f9-f2d4-c170b092893e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SFT\n",
            "Энтропия:  4.484833419615554\n",
            "Reward:  0.5356063388667384\n",
            "\n",
            "Hinge\n",
            "Энтропия:  3.597510553890052\n",
            "Reward:  2.4167400153650753\n",
            "\n",
            "Sigmoid\n",
            "Энтропия:  3.64248570190943\n",
            "Reward:  2.4014521733574243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Какие можно сделать выводы на основании результатов, представленных выше? Да особо никаких  ☹\n",
        "    \n",
        "У нас есть две метрики по которым мы можем замерять качество нашего обучения:\n",
        "1) Насколько хорошим, логичными, \"человечным\" генерируется текст. Самой простой метрикой этого является энтропия, которую мы и используем\n",
        "2) Насколько положительные генерируются отзывы\n",
        "\n",
        "И очевидно, что всегда придется искать некий trade-off. То есть чисто теоретически, мы могли бы сравнивать в таком сэттинге два различных лосса, если бы для каждого лосса сгенерировали большое количество моделей (меняя параметр бетта), множество которых образовывало на графике энтропия/качество некую кривую. И вот если бы кривая для hinge была строго выше кривой sigmoid тогда можно было бы говорить, что при равной энтропии у hinge выше оценки, или при равных оценках у hinge лучше получается тексты."
      ],
      "metadata": {
        "id": "I3aFd8yTZAfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LEVEL 2**"
      ],
      "metadata": {
        "id": "zbf5JnOcaTys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно было поменять код из готовой библиотеки форконув их репозиторий с гитхаб, поменять соответствующий файл и сделать git+htps://github.com/....Но это у меня не получилось, вылетала ошибка, которую не мог исправить\n",
        "\n",
        "Поэтому я решил просто сделать оболочку сферх класса, который мне нужно поменять.\n",
        "\n"
      ],
      "metadata": {
        "id": "kaP8pJaEaxl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вот собственно код:"
      ],
      "metadata": {
        "id": "f0xBmqYhbfch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "class MyDPOTrainer(DPOTrainer):\n",
        "\n",
        "    def __init__(self, alpha: float = None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        if alpha is None:\n",
        "            self.alpha = 1\n",
        "        else:\n",
        "            self.alpha = alpha\n",
        "\n",
        "    def dpo_loss(\n",
        "        self,\n",
        "        policy_chosen_logps: torch.FloatTensor,\n",
        "        policy_rejected_logps: torch.FloatTensor,\n",
        "        reference_chosen_logps: torch.FloatTensor,\n",
        "        reference_rejected_logps: torch.FloatTensor,\n",
        "        reference_free: bool = False,\n",
        "    ) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n",
        "        \"\"\"Compute the DPO loss for a batch of policy and reference model log probabilities.\n",
        "\n",
        "        Args:\n",
        "            policy_chosen_logps: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)\n",
        "            policy_rejected_logps: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)\n",
        "            reference_chosen_logps: Log probabilities of the reference model for the chosen responses. Shape: (batch_size,)\n",
        "            reference_rejected_logps: Log probabilities of the reference model for the rejected responses. Shape: (batch_size,)\n",
        "            reference_free: If True, we ignore the _provided_ reference model and implicitly use a reference model that assigns equal probability to all responses.\n",
        "\n",
        "        Returns:\n",
        "            A tuple of three tensors: (losses, chosen_rewards, rejected_rewards).\n",
        "            The losses tensor contains the DPO loss for each example in the batch.\n",
        "            The chosen_rewards and rejected_rewards tensors contain the rewards for the chosen and rejected responses, respectively.\n",
        "        \"\"\"\n",
        "        pi_logratios = policy_chosen_logps - policy_rejected_logps\n",
        "        if reference_free:\n",
        "            ref_logratios = 0\n",
        "        else:\n",
        "            ref_logratios = reference_chosen_logps - reference_rejected_logps\n",
        "\n",
        "        logits = pi_logratios - ref_logratios\n",
        "\n",
        "        # The beta is a temperature parameter for the DPO loss, typically something in the range of 0.1 to 0.5.\n",
        "        # We ignore the reference model as beta -> 0. The label_smoothing parameter encodes our uncertainty about the labels and\n",
        "        # calculates a conservative DPO loss.\n",
        "        if self.loss_type == \"sigmoid\":\n",
        "            losses = (\n",
        "                -F.logsigmoid(self.beta * logits) * (1 - self.label_smoothing)\n",
        "                - F.logsigmoid(-self.beta * logits) * self.label_smoothing\n",
        "            )\n",
        "        elif self.loss_type == \"hinge\":\n",
        "            losses = torch.relu(1 - self.beta * logits)\n",
        "        elif self.loss_type == \"ipo\":\n",
        "            # eqn (17) of the paper where beta is the regularization parameter for the IPO loss, denoted by tau in the paper.\n",
        "            losses = (logits - 1 / (2 * self.beta)) ** 2\n",
        "        elif self.loss_type == \"alpha\":\n",
        "            u1 = torch.exp(policy_chosen_logps - reference_chosen_logps)\n",
        "            u2 = torch.exp(policy_rejected_logps - reference_rejected_logps)\n",
        "            f = lambda x: (1 - x ** (-self.alpha)) / self.alpha\n",
        "            losses = -F.logsigmoid(self.beta*f(u1) - self.beta*f(u2))\n",
        "        elif self.loss_type == \"JSD\":\n",
        "            u1 = torch.exp(policy_chosen_logps - reference_chosen_logps)\n",
        "            u2 = torch.exp(policy_rejected_logps - reference_rejected_logps)\n",
        "            f = lambda x: torch.log((2 * x) / (1 + x))\n",
        "            losses = -F.logsigmoid(self.beta*f(u1) - self.beta*f(u2))\n",
        "        elif self.loss_type == \"FKL\":\n",
        "            u1 = torch.exp(policy_chosen_logps - reference_chosen_logps)\n",
        "            u2 = torch.exp(policy_chosen_logps - reference_chosen_logps)\n",
        "            f = lambda x: -1/x\n",
        "            losses = -F.logsigmoid(self.beta*f(u1) - self.beta*f(u2))\n",
        "        elif self.loss_type == \"RKL\":\n",
        "            u1 = torch.exp(policy_chosen_logps - reference_chosen_logps)\n",
        "            u2 = torch.exp(policy_chosen_logps - reference_chosen_logps)\n",
        "            f = lambda x: torch.log(x) + 1\n",
        "            losses = -F.logsigmoid(self.beta*f(u1) - self.beta*f(u2))\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown loss type: {self.loss_type}. Should be one of ['sigmoid', 'hinge', 'ipo', 'alpha', 'JSD']\")\n",
        "\n",
        "        chosen_rewards = self.beta * (policy_chosen_logps - reference_chosen_logps).detach()\n",
        "        rejected_rewards = self.beta * (policy_rejected_logps - reference_rejected_logps).detach()\n",
        "\n",
        "        return losses, chosen_rewards, rejected_rewards"
      ],
      "metadata": {
        "id": "Z7mcvah5bh3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Однако дальше я понял, что не успею сделать эксперименты с этими лосами, поэтому level 2 на этом заканчивается ☹"
      ],
      "metadata": {
        "id": "za2exsg7fuDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LEVEL 3**"
      ],
      "metadata": {
        "id": "4bVCcuNrg9pI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Самые гениальные (глупенькие) идеи на свете или размышления вслух:"
      ],
      "metadata": {
        "id": "lmJ3h6ZKA8_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Интересно рассмотреть AI-aligment с точки зрения теории социального выбора. Это такой раздел экономики/математики, где исследуется, как множество различных агентов с различными предпочтениями на определенном множестве объектов должны выбрать один из этих объектов (выбрать 3 лучших\\отранжировать), который будет удовлетворять большинство. В alignment, эта наука, возможно, может возникнуть в двух случаях:\n",
        "\n",
        "1) Мы хотим сделать крутой ИИ с человеческими ценностями. Но какие ценности выбрать, если у разных людей ценности разные? То есть, как нам следует выбрать набор ценностей \"победителей\". Но это больше философский вопрос, по которому статейку вряд ли напишешь.\n",
        "\n",
        "2) С более практической точки зрения, эта наука может возникнуть, если мы, например, решаем обучать несколько разных reward моделей для оценки различных характеристик (к примеру, отдельная reward модель для оценки агрессии ответа и модель для оценки логичной связанности ответа). Тогда у нас возможно будет возникать ситуация, когда одна модель имеет одни предпочтения на множестве ответов на промт, а другая модель - другие предпочтения. Как тогда нам нужно агрегировать их предпочтения? (Если это вообще нужно будет и проблемы такой на практике нет ¯\\_(ツ)_/¯ ).\n"
      ],
      "metadata": {
        "id": "4C_v51k6BCDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Интересно рассмотреть получше регуляризационный член в формуле лосса. Почему бы не брать квадрат от KL-дивергенции или любую другую монотонно возрастающую гладкую функцию на множестве положительных вещественных чисел, как это делают в классическом ML? Если же мы остаемся в контексте RL, то можно выбирать и не гладкие регуляризационные функции.\n",
        "\n",
        "Так или иначе, это нас приводит к задаче определения эффективной относительно нашей задачи метрики на множестве нейросетей с одинаковой архитектурой. Можно начинать с тупого квадрата разности весов нейросетки. Можно смотреть, насколько отличаются латентные представления нейросеток. И можно, наверное, придумать еще миллион других метрик; задача в том, чтобы они хорошо отражали конкретно нашу задачу."
      ],
      "metadata": {
        "id": "73WEiPxUEFxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ну тут уже очень практическая штука будет. Допустим, мы хотим научить LLM смешно шутить. Тогда нам не нужно будет собирать огромный датасет шуток и оценивать их. Это не круто. Круто сказать спасибо социальным сетям за то, что у них есть функция лайка. Другими словами, интересно понять, насколько может быть релевантным для обучения различных моделей (не только LLM) фидбек, который мы можем достать из социальных сетей."
      ],
      "metadata": {
        "id": "QWsXevJcNfUt"
      }
    }
  ]
}